{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rilschultz/CS167Notes/blob/main/Day24_RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCU4LbfsD1_q"
      },
      "source": [
        "# CS167: Day24\n",
        "## Recurrent Neural Networks\n",
        "\n",
        "#### CS167: Machine Learning, Spring 2023\n",
        "\n",
        "Tuesday, April 25th, 2023\n",
        "\n",
        "ðŸ“† [Course Schedule](https://docs.google.com/spreadsheets/d/e/2PACX-1vSvFV5Mz0_YZE1d5r3gQ8IMktE4cBAsJIlP30cl2GhEpSO0J-YWV62QokSDz-OcOCsEmxMuKpY0kVlR/pubhtml?gid=0&single=true) | ðŸ™‹[PollEverywhere](https://pollev.com/meredithmoore011) | ðŸ“œ [Syllabus](https://analytics.drake.edu/~moore/cs167_s23_syllabus.html) | ðŸ“¬ [CodePost Login](https://codepost.io/login)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC7QRAE4D1_t"
      },
      "source": [
        "# Admin Stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MRm5ojnD1_u"
      },
      "source": [
        "You should be working on:\n",
        "- Notebook #6 is due tonight by 11:59pm\n",
        "- [Project #2](https://classroom.github.com/a/gjJKXa78) is released today, due 5/5 by 11:59\n",
        "- Quiz #3 will be release on Tuesday 5/2 and will be due on Tuesday, 5/9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E2mhC9cD1_u"
      },
      "source": [
        "## Load your data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-zutdBsWD1_v",
        "outputId": "7adad077-ee49-4750-cd07-210bf93c5f8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSGxXFwLD1_w"
      },
      "source": [
        "## Quick Review:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df1KlYdnD1_w"
      },
      "source": [
        "# Pulling it all together:\n",
        "\n",
        "Okay, so we've talked about __image data__, __dot product__, __convolutions__, __max pooling__, and I've promised that we'll be able to pull off some computer vision. Let's connect the dots.\n",
        "\n",
        "Things to notice:\n",
        "- input is an image (in this case a color image, so 3 channels--red,green, and blue)\n",
        "- There are several filters, not just one.\n",
        "- `Conv2D` layers with `ReLU` are often followed by `maxpool` \n",
        "- Towards the end of the model, we switch to fully connected (`Dense`) layer\n",
        "- We have as many output nodes as we have classes to predict.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day22_cnn_architecture.svg?raw=1\" width=800/>\n",
        "</div>\n",
        "\n",
        "[[img src](https://developers.google.com/machine-learning/practica/image-classification)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nvJnkz-D1_x"
      },
      "source": [
        "## ðŸ™‹ PollEverywhere "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAeKICYHD1_x"
      },
      "source": [
        "# âœ¨ New Material"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD5Ui0G6D1_y"
      },
      "source": [
        "# Resources for Today:\n",
        "\n",
        "- [Intro to RNNs](https://towardsdatascience.com/a-brief-introduction-to-recurrent-neural-networks-638f64a61ff4)\n",
        "- [Unreasonable Effectiveness of RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVCl6jo1D1_y"
      },
      "source": [
        "# Types of Data:\n",
        "\n",
        "Which of the following can we model with what we've learned so far? Why or why not?\n",
        "- Predict the price of an airline ticket given the date, location, and weather\n",
        "- Predict the percent chance that a customer will churn (cancel whatever service a company provides) given their usage data.\n",
        "- Translate a phrase from one langauge to another\n",
        "- Predict the next word in a sentence\n",
        "- Predict if an image has a dog in it\n",
        "- Predict what was said in an audio recording\n",
        "- Generate text to caption an image\n",
        "- Predict what the price of a stock will be next week"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c27HsTK0D1_y"
      },
      "source": [
        "# So far our modeling has been limited:\n",
        "\n",
        "We've only worked with a certain type of data:\n",
        "- tabular data\n",
        "- no timeseries (the data does not need to be in a specific order)\n",
        "- the kind of predictions we have made have either been __classifications__ (binary or multiclass) or __regressions__.\n",
        "\n",
        "Can you think of other kinds of target variables we might be interested in modeling?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afX9_LQHD1_z"
      },
      "source": [
        "# What if my input isn't the same size of my output?\n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day23_input_output.png?raw=1\" width=1000/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaPKtF5MD1_z"
      },
      "source": [
        "## One to One:\n",
        "\n",
        "This is referred to as a Vanilla Neural Network, we input one training example and make one prediction.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day23_one2one.png?raw=1\" width=100/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2XKdS7lD1_0"
      },
      "source": [
        "## One to Many:\n",
        "\n",
        "Can anyone think of an example of a ML model that is __one to many__?\n",
        "- we input one training example, and output many predictions\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day23_one2many.png?raw=1\" width=200/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghBWhrpQD1_0"
      },
      "source": [
        "Image captioning:\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day23_image_caption.png?raw=1\" width=800/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5drAXpGDD1_0"
      },
      "source": [
        "## Many to One:\n",
        "\n",
        "Can anyone think of an example of a ML model that is __many to one__?\n",
        "- we input multiple things, and make one prediction from it\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day23_many2one.png?raw=1\" width=200/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6bWaGIAD1_1"
      },
      "source": [
        "Predicting a rating from a movie reivew\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day23_rating.png?raw=1\" width=800/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjoCO764D1_1"
      },
      "source": [
        "## Many to Many: \n",
        "\n",
        "Can anyone think of an example of a ML model that is __many to many__?\n",
        "- we input multiple things, and make multiple predictions from it\n",
        "- the input and output size do not need to be the same length\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day23_many2many.png?raw=1\" width=400/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWzq2ooOD1_1"
      },
      "source": [
        "Machine Translation:\n",
        "- translating from one language to another\n",
        "\n",
        "\"Hello my name is\" --> \"Hola me llamo\"\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day23_machine_translation.png?raw=1\" width=400/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtAjbnnDD1_2"
      },
      "source": [
        "## Many to Many (same size):\n",
        "\n",
        "Can anyone think of an example of a ML model that is __many to many__ with the same size input/output?\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day23_many2many2.png?raw=1\" width=200/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3dpBkkHD1_2"
      },
      "source": [
        "Sign-Language Detector:\n",
        "    \n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day23_asl.png?raw=1\" width=600/>\n",
        "</div>\n",
        "\n",
        "[[src](https://techcommunity.microsoft.com/t5/microsoft-teams-blog/introducing-sign-language-view-for-teams-meetings/ba-p/3671257)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_oXXIu9D1_2"
      },
      "source": [
        "# Recurrent Neural Networks\n",
        "\n",
        "__Recurrent Neural Networks__, also known as RNNs, are a class of neural networks that _allow previous outputs to be used as inputs_ while having hidden states.\n",
        "- RNNs are really good at processing sequential data.\n",
        "- RNNs can model all of the different configurations of input/output that we just went through\n",
        "- RNNs must use __context__ when making a prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUjRXwYKD1_2"
      },
      "source": [
        "# RNN\n",
        "\n",
        "RNNs are really good at modeling __sequential data__--that is, data where the current observation depends on previous observations, and thus observations are not independent from each other.\n",
        "\n",
        "Traditional neural networks view each observation as independent as the networks are not able to retain past or historical information. They have no memory of what happened in the past. \n",
        "\n",
        "RNNs achieve a sense of _memory_ by having a feedback loop. The feedback loop allows information to be passed within a layer, rather than only forward (as a feedforward neural network does). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCDPLBHMD1_2"
      },
      "source": [
        "## RNNs have loops.\n",
        "- Input $X_t$\n",
        "- Output $h_t$\n",
        "- Loop allows information to be passed from one step of the network to the next.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day23_rnn.png?raw=1\" width=700/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9zl5madD1_3"
      },
      "source": [
        "## An Example:\n",
        "\n",
        "Sometimes we only need to look at recent information to make a prediction:\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day23_rnn_time.png?raw=1\" width=600/>\n",
        "</div>\n",
        "\n",
        "Consider a langauge model trying to predict the next word based on the previous ones. Let's predict the last word to this sequence:\n",
        "- `\"The clouds are in the _______\"`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO35sK5XD1_3"
      },
      "source": [
        "We don't need much extra context to make a prediction. However, \n",
        "- `\"I grew up in France, I speak fluent _____\"`\n",
        "\n",
        "We can guess from recent information that it will be the name of a language, however, we need the context of France to make a prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4egioCBkD1_3"
      },
      "source": [
        "# Three main types of RNN:\n",
        "\n",
        "There are 3 main types of RNN that we'll breifly discuss:\n",
        "1. Traditiona Recurrent Neural Networks (RNN)\n",
        "2. Long Short Term Momry Recrurent Neural Network (LSTM)\n",
        "3. Gated Recurrent Unit Recurrent NEural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_9vpwW6D1_3"
      },
      "source": [
        "# Traditional Recurrent Neural Network:\n",
        "\n",
        "Each cell has 2 inputs:\n",
        "- the past and the present\n",
        "- the output from the previous cell $h_{t-1}$, and the current input into the cell $X_t$.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day23_unfolded_rnn.png?raw=1\" width=800/>\n",
        "</div>\n",
        "\n",
        "[[src](https://towardsdatascience.com/a-brief-introduction-to-recurrent-neural-networks-638f64a61ff4)]\n",
        "\n",
        "This is an image of the unfolded RNN to help understand what is going on. The length of the cell is equal to the number of time steps of the input sequence. \n",
        "\n",
        "In each cell the input of the current time step $x_t$, the hidden state of the previous cell $h_{t-1}$, and a bias are combined and then put through a $tanh$ activation function like so:\n",
        "\n",
        "$$h_t = tanh( W_x x_t + W_h h_{t-1} + b) $$\n",
        "\n",
        "Where $W_x$ and $W_h$ are weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dur6rpkrD1_3"
      },
      "source": [
        "## Advantages of Traditional RNNs\n",
        "\n",
        "Due to their short term memory, RNNs can handle sequential data and identify patterns in historical data.\n",
        "\n",
        "They can also handle inputs of varying lengths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4h_y2hyD1_4"
      },
      "source": [
        "## Disadvantages of RNNs\n",
        "\n",
        "The RNN suffers from the __vanishing gradient__ problem. \n",
        "- The graidents that are used to update the weights during backpropagation become very small\n",
        "- Multiplying weights with a graident that is so close to zero prevents the network from learning new weights \n",
        "- This stops the learning and results in the RNN forgetting what is seen in longer sequences\n",
        "- This problem gets worse with the more layers the network has."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fXsNRDbD1_4"
      },
      "source": [
        "# Long-Short-Term-Memory (LSTM)\n",
        "\n",
        "LSTMs are a special type of RNN which tackle the __vanishing gradient__ problem. \n",
        "\n",
        "Essentially, the LSTM adds 3 gates:\n",
        "- __forget gate__: decies how much long-term memory shall be kept\n",
        "- __input gate__: decides which information shall be added to the long-term memory\n",
        "- __output gate__: decides which parts of the cell state build the output, i.e. it's responsible for the short term memory\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day23_lstm.png?raw=1\" width=800/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXWunS92D1_4"
      },
      "source": [
        "## Advantages of  LSTMs\n",
        "\n",
        "Can capture both the short and long term patterns of a seuqnce.\n",
        "\n",
        "These are some of the most used RNNs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3yQARf_D1_4"
      },
      "source": [
        "## Disadvantages of LSTMs\n",
        "\n",
        "Because LSTMs add complexity, they also are computationally more expensive, leading to longer training times. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os-K8W6ED1_4"
      },
      "source": [
        "# Gated Recurrent Unit (GRU)\n",
        "\n",
        "Similar to LSTMs, the GRU solves the vanishing gradient problem, but they do so using fewer gates--making them effective, and fast.\n",
        "\n",
        "GRUs have two gates:\n",
        "- a __reset gate__ which is responsible for the short-term memory as it decides how much past information is kept and disregarded\n",
        "- an __update gate__ which is responsible for the long-term memory and is comparable to the LSTMs forget gate.\n",
        "<div>\n",
        "<img src=\"https://github.com/merriekay/S23-CS167-Notes/blob/main/images/day23_gru.png?raw=1\" width=800/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juzbyRw_D1_4"
      },
      "source": [
        "## Advantages of  GRUs\n",
        "\n",
        "Solve vanishing gradient problem\n",
        "\n",
        "Less computationally expensive than LSTMs, which makes them faster to train."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kH_n6IMD1_4"
      },
      "source": [
        "## Disadvantages of GRUs\n",
        "\n",
        "GRUs do not have a separate hidden and cell state, so they might not be able to consider observations as far into the past as the LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obwPeeJ_D1_5"
      },
      "source": [
        "# Project #2:\n",
        "\n",
        "Very similar to Project #1, but I expect you to use some of the methods that we've talked about since project #1:\n",
        "- PCA\n",
        "- SVM\n",
        "- Perceptron\n",
        "- MLP\n",
        "- Neural Networks\n",
        "- Convolutional Neural Networks\n",
        "- Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C__URVDRD1_5"
      },
      "source": [
        "# Project #2 Description:\n",
        "\n",
        "1. __Problem__: be sure to tell me what kind of machine learning is going on, what your target variable is, what your predictor variables are. What are you going to test in this experiment? What are your hypotheses (e.g. a model with 5 layers will perform better than a model with 3 layers)\n",
        "2. __Data Preparation__: explain your data prep... what needed to be done to get your data in shape for your experiments?\n",
        "3. __Research__: your code/experiments go here, be sure to include a couple graphs\n",
        "4. __Analysis__: what did you discover? How did your hypotheses fare? What insights/recommendations do you have? What did you find that was interesting? Which model was your bets model, which models didn't work well? Why do you think this is? In general, describe your experiment, the results, and what they mean.\n",
        "5. __Bumps in the Road__: What challenges did you encouter? How did you overcome these challenges?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI8CiemUD1_5"
      },
      "source": [
        "## Getting Started:\n",
        "\n",
        "Look for a dataset, use a different one than you used in Project #1. \n",
        "\n",
        "Think about what kinds of hypotheses you might test, and what kinds of models you think might perform well. \n",
        "\n",
        "I'm not giving you a chart to fill in like last time--which models you use are up to you. \n",
        "\n",
        "### Use the rest of class time to get started on this. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc0R_0PpD1_5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}